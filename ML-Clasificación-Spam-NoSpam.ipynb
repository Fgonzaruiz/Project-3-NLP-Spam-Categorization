{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7d42505",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Fgonz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Fgonz\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from wordcloud import WordCloud\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "import numpy as np \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Metricas\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import jaccard_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import jaccard_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import precision_score, recall_score, jaccard_score, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, jaccard_score, precision_score, recall_score, f1_score, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from imblearn.over_sampling import SMOTE \n",
    "import pickle\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report, confusion_matrix, jaccard_score, accuracy_score, precision_score, recall_score, f1_score, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b71cd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import AdaBoostClassifier\n",
    "import DecisionTreeClassifier\n",
    "import FreqDist\n",
    "import GaussianNB\n",
    "import GradientBoostingClassifier\n",
    "import GridSearchCV\n",
    "import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pickle\n",
    "import randomforestclassifier\n",
    "import seaborn as sns\n",
    "import SVC\n",
    "import sklearn\n",
    "import SMOTE\n",
    "import TfidfVectorizer\n",
    "import wordcloud\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import jaccard_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from wordcloud import WordCloud\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dce8ae09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_emails.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8166dc2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>spam</th>\n",
       "      <th>email_length</th>\n",
       "      <th>text_prepr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: naturally irresistible your corporate...</td>\n",
       "      <td>1</td>\n",
       "      <td>1484</td>\n",
       "      <td>subject naturally irresistible corporate ident...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: the stock trading gunslinger  fanny i...</td>\n",
       "      <td>1</td>\n",
       "      <td>598</td>\n",
       "      <td>subject stock trading gunslinger fanny merrill...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: unbelievable new homes made easy  im ...</td>\n",
       "      <td>1</td>\n",
       "      <td>448</td>\n",
       "      <td>subject unbelievable new homes made easy im wa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: 4 color printing special  request add...</td>\n",
       "      <td>1</td>\n",
       "      <td>500</td>\n",
       "      <td>subject color printing special request additio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: do not have money , get software cds ...</td>\n",
       "      <td>1</td>\n",
       "      <td>235</td>\n",
       "      <td>subject money get software cds software compat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  spam  email_length  \\\n",
       "0  Subject: naturally irresistible your corporate...     1          1484   \n",
       "1  Subject: the stock trading gunslinger  fanny i...     1           598   \n",
       "2  Subject: unbelievable new homes made easy  im ...     1           448   \n",
       "3  Subject: 4 color printing special  request add...     1           500   \n",
       "4  Subject: do not have money , get software cds ...     1           235   \n",
       "\n",
       "                                          text_prepr  \n",
       "0  subject naturally irresistible corporate ident...  \n",
       "1  subject stock trading gunslinger fanny merrill...  \n",
       "2  subject unbelievable new homes made easy im wa...  \n",
       "3  subject color printing special request additio...  \n",
       "4  subject money get software cds software compat...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d91025e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text_prepr'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9f44bae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11300, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44497ce",
   "metadata": {},
   "source": [
    "# MÉTODOS Y SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d057b00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (9040, 36489)\n",
      "Test Shape: (2260, 36489)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['text_prepr'])\n",
    "y = df['spam']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 42, stratify = y)\n",
    "filename = 'vectorizer.pkl'\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(vectorizer, file,-1)\n",
    "\n",
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Test Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcd6a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modelos(X_train, y_train, X_test, y_test):\n",
    "    modelos = [LogisticRegression(), RandomForestClassifier(),\n",
    "               AdaBoostClassifier(), GradientBoostingClassifier(), SVC(kernel = \"linear\"), DecisionTreeClassifier()]\n",
    "\n",
    "    data = list()\n",
    "\n",
    "    for model in modelos:\n",
    "\n",
    "        print(str(model))\n",
    "\n",
    "        model.fit(X_train, y_train)\n",
    "        yhat = model.predict(X_test)\n",
    "\n",
    "        jac = jaccard_score(y_test, yhat, average = \"macro\")\n",
    "        acc = accuracy_score(y_test, yhat)\n",
    "        pre = precision_score(y_test, yhat, average = \"macro\")\n",
    "        rec = recall_score(y_test, yhat, average = \"macro\")\n",
    "        f1_ = f1_score(y_test, yhat, average = \"macro\")\n",
    "        roc = roc_auc_score(y_test, yhat)\n",
    "        con = confusion_matrix(y_test, yhat)\n",
    "\n",
    "        data.append([str(model), jac, acc, pre, rec, f1_, roc, con, model])\n",
    "\n",
    "    df_metricas = pd.DataFrame(data = data,\n",
    "                               columns = [\"name\", \"jaccard\", \"accuracy\", \"precision\", \"recall\", \"f1\", \"roc_auc\", \"cm\", \"model\"])\n",
    "    return df_metricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "877b3a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression()\n",
      "RandomForestClassifier()\n",
      "AdaBoostClassifier()\n",
      "GradientBoostingClassifier()\n",
      "SVC(kernel='linear')\n",
      "DecisionTreeClassifier()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "oversampling = SMOTE(sampling_strategy=0.30)\n",
    "X_balanceado, y_balanceado = oversampling.fit_resample(X, y) # Se obtienen nuevos X e y balanceados\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_balanceado, y_balanceado, test_size = 0.3, random_state = 0)\n",
    "\n",
    "df_metricas = modelos(X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa354cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>jaccard</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>cm</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "      <td>0.937847</td>\n",
       "      <td>0.978504</td>\n",
       "      <td>0.977341</td>\n",
       "      <td>0.958585</td>\n",
       "      <td>0.967584</td>\n",
       "      <td>0.958585</td>\n",
       "      <td>[[2792, 18], [59, 713]]</td>\n",
       "      <td>SVC(kernel='linear')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.932156</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>0.983439</td>\n",
       "      <td>0.948122</td>\n",
       "      <td>0.964462</td>\n",
       "      <td>0.948122</td>\n",
       "      <td>[[2806, 4], [79, 693]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_features='auto', r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "      <td>0.896529</td>\n",
       "      <td>0.962312</td>\n",
       "      <td>0.942659</td>\n",
       "      <td>0.946386</td>\n",
       "      <td>0.944506</td>\n",
       "      <td>0.946386</td>\n",
       "      <td>[[2738, 72], [63, 709]]</td>\n",
       "      <td>DecisionTreeClassifier()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.884123</td>\n",
       "      <td>0.959799</td>\n",
       "      <td>0.965976</td>\n",
       "      <td>0.914251</td>\n",
       "      <td>0.937160</td>\n",
       "      <td>0.914251</td>\n",
       "      <td>[[2794, 16], [128, 644]]</td>\n",
       "      <td>LogisticRegression()</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier()</td>\n",
       "      <td>0.864081</td>\n",
       "      <td>0.951703</td>\n",
       "      <td>0.947638</td>\n",
       "      <td>0.906743</td>\n",
       "      <td>0.925245</td>\n",
       "      <td>0.906743</td>\n",
       "      <td>[[2770, 40], [133, 639]]</td>\n",
       "      <td>([DecisionTreeRegressor(criterion='friedman_ms...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>0.844834</td>\n",
       "      <td>0.944165</td>\n",
       "      <td>0.936074</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>0.913444</td>\n",
       "      <td>0.894892</td>\n",
       "      <td>[[2758, 52], [148, 624]]</td>\n",
       "      <td>(DecisionTreeClassifier(max_depth=1, random_st...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name   jaccard  accuracy  precision    recall  \\\n",
       "4          SVC(kernel='linear')  0.937847  0.978504   0.977341  0.958585   \n",
       "1      RandomForestClassifier()  0.932156  0.976829   0.983439  0.948122   \n",
       "5      DecisionTreeClassifier()  0.896529  0.962312   0.942659  0.946386   \n",
       "0          LogisticRegression()  0.884123  0.959799   0.965976  0.914251   \n",
       "3  GradientBoostingClassifier()  0.864081  0.951703   0.947638  0.906743   \n",
       "2          AdaBoostClassifier()  0.844834  0.944165   0.936074  0.894892   \n",
       "\n",
       "         f1   roc_auc                        cm  \\\n",
       "4  0.967584  0.958585   [[2792, 18], [59, 713]]   \n",
       "1  0.964462  0.948122    [[2806, 4], [79, 693]]   \n",
       "5  0.944506  0.946386   [[2738, 72], [63, 709]]   \n",
       "0  0.937160  0.914251  [[2794, 16], [128, 644]]   \n",
       "3  0.925245  0.906743  [[2770, 40], [133, 639]]   \n",
       "2  0.913444  0.894892  [[2758, 52], [148, 624]]   \n",
       "\n",
       "                                               model  \n",
       "4                               SVC(kernel='linear')  \n",
       "1  (DecisionTreeClassifier(max_features='auto', r...  \n",
       "5                           DecisionTreeClassifier()  \n",
       "0                               LogisticRegression()  \n",
       "3  ([DecisionTreeRegressor(criterion='friedman_ms...  \n",
       "2  (DecisionTreeClassifier(max_depth=1, random_st...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metricas.sort_values(by='roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aaf708eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape: (8358, 36489)\n",
      "Test Shape: (3582, 36489)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train Shape: {X_train.shape}\")\n",
    "print(f\"Test Shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd73d02a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc = df_metricas[\"model\"][1]\n",
    "\n",
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a6ec44b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_features='auto', random_state=1294263765)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc.estimators_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "392fe006",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[585,\n",
       " 273,\n",
       " 587,\n",
       " 609,\n",
       " 554,\n",
       " 602,\n",
       " 565,\n",
       " 538,\n",
       " 606,\n",
       " 522,\n",
       " 555,\n",
       " 568,\n",
       " 600,\n",
       " 616,\n",
       " 415,\n",
       " 344,\n",
       " 581,\n",
       " 581,\n",
       " 395,\n",
       " 592,\n",
       " 512,\n",
       " 376,\n",
       " 250,\n",
       " 557,\n",
       " 374,\n",
       " 302,\n",
       " 604,\n",
       " 584,\n",
       " 578,\n",
       " 568,\n",
       " 531,\n",
       " 379,\n",
       " 606,\n",
       " 608,\n",
       " 540,\n",
       " 619,\n",
       " 311,\n",
       " 260,\n",
       " 599,\n",
       " 557,\n",
       " 215,\n",
       " 566,\n",
       " 300,\n",
       " 580,\n",
       " 600,\n",
       " 547,\n",
       " 575,\n",
       " 589,\n",
       " 569,\n",
       " 519,\n",
       " 571,\n",
       " 594,\n",
       " 529,\n",
       " 443,\n",
       " 537,\n",
       " 569,\n",
       " 533,\n",
       " 304,\n",
       " 425,\n",
       " 531,\n",
       " 600,\n",
       " 508,\n",
       " 584,\n",
       " 564,\n",
       " 605,\n",
       " 568,\n",
       " 421,\n",
       " 600,\n",
       " 352,\n",
       " 579,\n",
       " 473,\n",
       " 247,\n",
       " 520,\n",
       " 374,\n",
       " 526,\n",
       " 623,\n",
       " 626,\n",
       " 242,\n",
       " 571,\n",
       " 622,\n",
       " 580,\n",
       " 426,\n",
       " 579,\n",
       " 454,\n",
       " 568,\n",
       " 552,\n",
       " 584,\n",
       " 232,\n",
       " 302,\n",
       " 533,\n",
       " 626,\n",
       " 589,\n",
       " 271,\n",
       " 342,\n",
       " 541,\n",
       " 601,\n",
       " 215,\n",
       " 244,\n",
       " 603,\n",
       " 626]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[tree.get_depth() for tree in rfc.estimators_]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58272535",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4196b3b3",
   "metadata": {},
   "source": [
    "# GridSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbd6727e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 500],\n",
    "    'max_depth': [None, 200, 500, 700],\n",
    "    'min_samples_split': [20, 30, 40],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    \"max_leaf_nodes\" : [800, 1000, 1200, None] ,\n",
    "    \"max_features\" : [\"sqrt\", \"log2\", None],\n",
    "    \"criterion\" : [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=10, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Mejores parámetros encontrados: \", grid_search.best_params_)\n",
    "print(\"Mejor puntuación en la validación cruzada: \", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90c7234c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest(df, target, leaf=None, split=None, max_depth=None, n_estimators=None, criterion=None, max_leaf_nodes=None, max_features=None):\n",
    "\n",
    "    model = RandomForestClassifier(min_samples_leaf=leaf, \n",
    "                                   min_samples_split=split, \n",
    "                                   max_depth=max_depth, \n",
    "                                   n_estimators=n_estimators,\n",
    "                                   max_leaf_nodes=max_leaf_nodes,\n",
    "                                   criterion=criterion,\n",
    "                                   max_features=max_features\n",
    "                                   )\n",
    "    \n",
    "   # X_train = X_train.toarray()\n",
    "    #X_test = X_test.toarray()\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    filename = 'model.pkl'\n",
    "    with open(\"model.pkl\", \"wb\") as file:\n",
    "        pickle.dump(model, file, -1)\n",
    "    yhat = model.predict(X_test)\n",
    "    \n",
    "    print(\"Jaccard Index:\", jaccard_score(y_test, yhat, average = \"macro\"))\n",
    "    print(\"Accuracy:\"     , accuracy_score(y_test, yhat))\n",
    "    print(\"Precisión:\"    , precision_score(y_test, yhat, average = \"macro\"))\n",
    "    print(\"Sensibilidad:\" , recall_score(y_test, yhat, average = \"macro\"))\n",
    "    print(\"F1-score:\"     , f1_score(y_test, yhat, average = \"macro\"))\n",
    "    print(\"ROC AUC:\"      , roc_auc_score(y_test, yhat)) \n",
    "    print(\"Accuracy:\", accuracy_score(y_test, yhat))\n",
    "    print(\"Classification Report:\", classification_report(y_test, yhat))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc69bf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "sadasd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d180c9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest(df, \"spam\", leaf = 1 , split = 2, max_depth = None, n_estimators = 500, criterion=None, max_leaf_nodes=None, max_features=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae38f6d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
